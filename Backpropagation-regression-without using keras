import numpy as np
import pandas as pd

#I am creating my own dataet of cgpa,resume score and then training the neural network using backpropagation

df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile_score','lpa'])

df

def initialize_parameters(layer_dims):
    np.random.seed(3)
    parameters={}
    L=len(layer_dims)
    
    for l in range(1,L)"
          parameters['W'+str(l)]=np.ones((layer_dims[l-1],layer_dims[l]))*0.1
          parameters['b'+str(l)]=np.zeros((layer_dims[l],1))
    return parameters
    
    
    
initialize_parameters([2,2,1])


def linear_forward(A_prev,W,b):
    z=np.dot(W.T,A_prev)+b
    return z
    
   
#function for forward propagation

def L_layer_forward(X,parameters):
    A=X
    L=len(parameters)
    
    for l in range(1,L+1):
         A_prev=A
         W1=parameters['W'+str(l)]
         b1=parameters['b'+str(l)]
         print("A"+str(l-1)+": ",A_prev)
         print("W"+str(l)+": ",W1)
         print("b"+str(l)+": ",b1)
         print("--"*20)
         
         A=linear_forward(A_prev,W1,b1)
         print("A"+str(l)+": ",A)
         print("**"*20)
         
    return A,A_prev
    
    
 X=df[['cgpa','profile_score']].values[0].reshape(2,1)
 y=df[['lpa']].values[0][0]
 
 parameters=initialize_parameters([2,2,1])
 
y_hat,A1 = L_layer_forward(X,parameters)
y_hat=y_hat[0][0]

 
 
 
 
 #function for backpropagation
 
 def update_parameters(parameters,y,y_hat,A1,X):
     parameters['W2'][0][0]=parameters['W2'][0][0]+(0.001*2*(y-y_hat)*A1[0][0])
     parameters['W2'][1][0]=parameters['W2'][1][0]+(0.001*2*(y-y_hat)*A1[1][0])
     parameters['b2'][0][0]=parameters['W2'][1][0]+(0.001*2*(y-y_hat))
     
     parameters['W1'][0][0]=parameters['W1'][0][0]+(0.001*2*(y-y_hat)*parameters['W2'][0][0]*X[0][0])
     parameters['W1'][0][1]=parameters['W1'][0][1]+(0.001*2*(y-y_hat)*parameters['W2'][0][0]*X[1][0])
     parameters['b1'][0][0]=parameters['b1'][0][0]+(0.001*2*(y-y_hat)*parameters['W2'][0][0])
     
     parameters['W1'][1][0]=parameters['W1'][1][0]+(0.001*2*(y-y_hat)*parameters['W2'][1][0]*X[0][0])
     parameters['W1'][1][1]=parameters['W1'][1][1]+(0.001*2*(y-y_hat)*parameters['W2'][1][0]*X[1][0])
     parameters['b1'][1][0]=parameters['b1'][1][0]+(0.001*2*(y-y_hat)*parameters['W2'][1][0])
     
     
     
     
 
 update_parameters(parameters,y,y_hat,A1,X)
 
 parameters
 
 
 #Now for the second student
 
 X=df[['cgpa','profile_score']].values[1].reshape(2,1)
 y=df[['lpa']].values[1][0]
 

 
y_hat,A1 = L_layer_forward(X,parameters)
y_hat=y_hat[0][0]

 update_parameters(parameters,y,y_hat,A1,X)
 
 parameters
 
 #For third student
 
 
 
 X=df[['cgpa','profile_score']].values[2].reshape(2,1)
 y=df[['lpa']].values[2][0]
 

 
y_hat,A1 = L_layer_forward(X,parameters)
y_hat=y_hat[0][0]

 update_parameters(parameters,y,y_hat,A1,X)
 
 parameters
 
 #For fourth student
 
 
 
 X=df[['cgpa','profile_score']].values[3].reshape(2,1)
 y=df[['lpa']].values[3][0]
 

 
y_hat,A1 = L_layer_forward(X,parameters)
y_hat=y_hat[0][0]

 update_parameters(parameters,y,y_hat,A1,X)
 
 parameters
 
 
 #For fifth student
 
 
 
 X=df[['cgpa','profile_score']].values[4].reshape(2,1)
 y=df[['lpa']].values[4][0]
 

 
y_hat,A1 = L_layer_forward(X,parameters)
y_hat=y_hat[0][0]

 update_parameters(parameters,y,y_hat,A1,X)
 
 parameters
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 #Single piece of code for epoch implementation
 
 parameters=initialize_parameters([2,2,1])
 epochs=10
 
 for i in range(epochs):
        Loss=[]
        
        for j in range(df.shape[0]):
               X=df[['cgpa','profile_score']].values[j].reshape(2,1)
               y=df[['lpa']].values[j][0]
               
               #Parameter initialization
               
               y_hat,A1=L_layer_forward(X,parameters)
               y_hat=y_hat[0][0]
               
               update_parameters(parameters,y,y_hat,A1,X)
               
               Loss.append((y-y_hat)**2)
               
               print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())
               
             
             
parameters
